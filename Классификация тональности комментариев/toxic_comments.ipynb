{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Импорты\" data-toc-modified-id=\"Импорты-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Импорты</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Лемматизация\" data-toc-modified-id=\"Лемматизация-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Лемматизация</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разбиение-на-выборки\" data-toc-modified-id=\"Разбиение-на-выборки-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Разбиение на выборки</a></span></li><li><span><a href=\"#Получение-TF-IDF-для-корпуса-текста\" data-toc-modified-id=\"Получение-TF-IDF-для-корпуса-текста-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Получение TF-IDF для корпуса текста</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Boosting\" data-toc-modified-id=\"Boosting-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Boosting</a></span></li><li><span><a href=\"#Вert\" data-toc-modified-id=\"Вert-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Вert</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация тональности комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Значение метрики качества *F1* должно быть не меньше 0.75.** \n",
    "\n",
    "**Основные шаги по выполнению проекта**\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Вывожы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но можно попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Danil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Danil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# from pymystem3 import Mystem тормозит сильно\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   Explanation\\nWhy the edits made under my usern...      0\n",
       "1   D'aww! He matches this background colour I'm s...      0\n",
       "2   Hey man, I'm really not trying to edit war. It...      0\n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4   You, sir, are my hero. Any chance you remember...      0\n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7   Your vandalism to the Matt Shirvington article...      0\n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9   alignment on this subject and which are contra...      0\n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0\n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0\n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "13  Before you start throwing accusations and warn...      0\n",
       "14  Oh, and the girl above started her arguments w...      0\n",
       "15  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...      0\n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "17   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski      0\n",
       "18  The Mitsurugi point made no sense - why not ar...      0\n",
       "19  Don't mean to bother you \\n\\nI see that you're...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('datasets/toxic_comments.csv')\n",
    "    \n",
    "df.info()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отчистим сообщения\n",
    "# сначала заменим все, что не буквы пробелами\n",
    "# затем разобьем все на слова и объединим через пробел (чтобы убрать лишние пробелы)\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(re.sub(r'[^a-zA-Z]', ' ', x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация \n",
    "\n",
    "Используемый мной ранее pymystem3 в данном случае не поможет, так как он работает только с руским текстом.\n",
    "\n",
    "Лемматизатор нужно применять к словам, а не ко всему тексту сразу.\n",
    "Использовал list comprehension для лемматизации, чтобы пройтись по каждому слову.\n",
    "    \n",
    "Думаю вместо очистки можно было воспользоваться nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation Why the edits made under my userna...      0\n",
       "1  D aww He match this background colour I m seem...      0\n",
       "2  Hey man I m really not trying to edit war It s...      0\n",
       "3  More I can t make any real suggestion on impro...      0\n",
       "4  You sir are my hero Any chance you remember wh...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# лемматизируем\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['text'] = df['text'].apply(\n",
    "    lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.split()]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на выборки\n",
    "\n",
    "Приводить тексты к юникоду не имеет смысла, так как они все на английском. Это может привести к падению ядра из-за увеличения объема занимаемой памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text']\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656,)\n",
      "(31915,)\n",
      "0    0.89832\n",
      "1    0.10168\n",
      "Name: toxic, dtype: float64\n",
      "0    0.898324\n",
      "1    0.101676\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corpus_train, corpus_test, target_train, target_test = train_test_split(\n",
    "    corpus, target, test_size=0.2, stratify=target, random_state=RANDOM_STATE)\n",
    "\n",
    "print(corpus_train.shape)\n",
    "print(corpus_test.shape)\n",
    "print(target_train.value_counts(normalize=True))\n",
    "print(target_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение TF-IDF для корпуса текста\n",
    "\n",
    "Скачаем стоп-слова и обучим векторизатор только на тренировочной части выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Danil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# получение стоп-слов \n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# обучаем только на тренировочной выборке\n",
    "tf_idf_train = tf_idf.fit_transform(corpus_train)\n",
    "tf_idf_test = tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "\n",
    "Внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно.  \n",
    "Для избежания такого эффекта можно использовать пйплайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию для вывода основных метрик качества класификации\n",
    "def classification_metrics(target, predictions):\n",
    "    print(f'Accuracy:  {accuracy_score(target, predictions):.2f}')\n",
    "    print(f'Precision: {precision_score(target, predictions):.2f}')\n",
    "    print(f'Recall:    {recall_score(target, predictions):.2f}')\n",
    "    print(f'F1:        {f1_score(target, predictions):.2f}')\n",
    "    print(f'ROC AUC:   {roc_auc_score(target, predictions):.2f}')\n",
    "    print('_'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lr = LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE).fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 {color: black;background-color: white;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 pre{padding: 0;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-toggleable {background-color: white;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-item {z-index: 1;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-parallel-item:only-child::after {width: 0;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-44b4a12b-9e16-4e72-b09b-968558eb51c2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-44b4a12b-9e16-4e72-b09b-968558eb51c2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                    random_state=12345))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9972d048-8d81-4fc9-aa03-c2b8355e3cb0\" type=\"checkbox\" ><label for=\"9972d048-8d81-4fc9-aa03-c2b8355e3cb0\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                    random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"56e92057-7a92-4f05-bce2-1ce244ffb9ab\" type=\"checkbox\" ><label for=\"56e92057-7a92-4f05-bce2-1ce244ffb9ab\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a893f5e2-c260-4d2e-9055-376945813d92\" type=\"checkbox\" ><label for=\"a893f5e2-c260-4d2e-9055-376945813d92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('model',\n",
       "                 LogisticRegression(class_weight='balanced',\n",
       "                                    random_state=12345))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим пайплайн для возможности корректной кросс-валидации\n",
    "pipe_lr = Pipeline(\n",
    "    [('tf_idf', TfidfVectorizer(stop_words=stop_words)),\n",
    "     ('model', LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "pipe_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7452011405904526"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# произведем кросс-валидацию по метрике F1\n",
    "cross_val_score(pipe_lr, corpus_train, target_train, cv=5, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7479519895467238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model_lr, tf_idf_train, target_train, cv=5, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.94\n",
      "Precision: 0.68\n",
      "Recall:    0.85\n",
      "F1:        0.76\n",
      "ROC AUC:   0.90\n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "classification_metrics(target_test, model_lr.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока не дотягиваем до требуемого минимального значения метрики F1 = 0.75 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменения:\n",
    "1) В предыдущей редакции я никак не учитывал дисбаланс классов. Сейчас добавил праметр class_weight и качество логистической регрессии возрасло до целевого значения F1.  \n",
    "2) Добавил pipeline для кросс-валидации. Ради интереса сравинил метрики - есть различия в тысячных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model_dtc = DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight='balanced').fit(tf_idf_train, target_train)\n",
    "# cross_val_score(model_dtc, tf_idf_train, target_train, cv=5, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model_rfc = RandomForestClassifier(random_state=RANDOM_STATE).fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 {color: black;background-color: white;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 pre{padding: 0;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-toggleable {background-color: white;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-estimator:hover {background-color: #d4ebff;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-item {z-index: 1;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-parallel-item:only-child::after {width: 0;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-3acdc6c7-db7d-40df-9571-f1e53029fd67 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-3acdc6c7-db7d-40df-9571-f1e53029fd67\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"50a70b21-5dfa-461c-8a83-43102b1cad63\" type=\"checkbox\" checked><label for=\"50a70b21-5dfa-461c-8a83-43102b1cad63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', random_state=12345)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lgbm = LGBMClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_STATE)\n",
    "model_lgbm.fit(tf_idf_train, target_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-1f009351-77d1-480b-af11-4379c606d01b {color: black;background-color: white;}#sk-1f009351-77d1-480b-af11-4379c606d01b pre{padding: 0;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-toggleable {background-color: white;}#sk-1f009351-77d1-480b-af11-4379c606d01b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-1f009351-77d1-480b-af11-4379c606d01b label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-1f009351-77d1-480b-af11-4379c606d01b label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-1f009351-77d1-480b-af11-4379c606d01b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-1f009351-77d1-480b-af11-4379c606d01b input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-1f009351-77d1-480b-af11-4379c606d01b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-estimator:hover {background-color: #d4ebff;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-item {z-index: 1;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-parallel-item:only-child::after {width: 0;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-1f009351-77d1-480b-af11-4379c606d01b div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-1f009351-77d1-480b-af11-4379c606d01b\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2fa32b4b-929a-44e6-b98c-2bf7b7126020\" type=\"checkbox\" ><label for=\"2fa32b4b-929a-44e6-b98c-2bf7b7126020\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1392ca96-c94f-4e29-bad2-d11cb8ea4bea\" type=\"checkbox\" ><label for=\"1392ca96-c94f-4e29-bad2-d11cb8ea4bea\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1034208f-01a7-4560-8080-5c40e3d67a7e\" type=\"checkbox\" ><label for=\"1034208f-01a7-4560-8080-5c40e3d67a7e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('model',\n",
       "                 LGBMClassifier(class_weight='balanced', random_state=12345))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lgbm = Pipeline([\n",
    "    ('tf_idf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('model', LGBMClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "pipe_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7312466239766078"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cross_val_score(pipe_lgbm, corpus_train, target_train, cv=3, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.94\n",
      "Precision: 0.68\n",
      "Recall:    0.80\n",
      "F1:        0.74\n",
      "ROC AUC:   0.88\n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "classification_metrics(target_test, model_lgbm.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока я не разобрался как добавить pipeline для кросс-валидации из библиотеки catboost.  \n",
    "Поэтому я решил заменить catboost на LGBM.\n",
    "Оставлю блоки ниже закомментированным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model_cbс = CatBoostClassifier(\n",
    "#     iterations=100, learning_rate=0.9, depth=4, loss_function='Logloss', \n",
    "#     auto_class_weights='Balanced', random_state=RANDOM_STATE)\n",
    "# model_cbс.fit(tf_idf_train, target_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # кроссвалидация из библиоткеи CatBoost\n",
    "\n",
    "# params = {'iterations': 100,\n",
    "#           'loss_function': 'Logloss',\n",
    "#          'learning_rate': 0.9,\n",
    "#          'depth': 4}\n",
    "\n",
    "# cv_data = cv(\n",
    "#     params=params,\n",
    "#     pool=Pool(tf_idf_train, label=target_train),\n",
    "#     fold_count=3, \n",
    "#     shuffle=True, # Перемешаем наши данные\n",
    "#     plot=True, # визуализатор\n",
    "#     verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличении скорости обучения у catboost позволило добится серрьезного улучшение качества. При learning_rate = 0.1, F1 = 0,67; при learning_rate = 1, F1 = 0,77;\n",
    "\n",
    "Что немного для меня странно - в предыдущех проектах использовал небольшие значения этого коэффициента (но там были задачи регрессии). Возможно это связано с небольшим количестовм итераций. Здесь все довольно дого считается, поэтому ограничился 100 итерациями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вert\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться (как в моем случае).\n",
    "\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевые показатели качества по метрике F1 удалось достичь c помощью LightGBM.  \n",
    "Случайный лес я в итоге не использовал - он всегда считается у меня достаточно долго.\n",
    "\n",
    "Гиперпараметры пока перебирал только вручную. Потенциально для целей подбора можно использовать RandomizedSearch или OptunaSearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
